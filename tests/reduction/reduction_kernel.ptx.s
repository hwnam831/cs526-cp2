//
// Generated by LLVM NVPTX Back-End
//

.version 5.0
.target sm_61, texmode_independent
.address_size 64

	// .globl	reduction               // -- Begin function reduction
                                        // @reduction
.entry reduction(
	.param .u64 .ptr .global .align 4 reduction_param_0,
	.param .u64 .ptr .global .align 4 reduction_param_1,
	.param .u32 reduction_param_2
)
{
	.reg .f32 	%f<4>;
	.reg .b32 	%r<11>;
	.reg .b64 	%rd<15>;

// %bb.0:                               // %entry
	ld.param.u64 	%rd1, [reduction_param_0];
	ld.param.u64 	%rd2, [reduction_param_1];
	mov.u32 	%r1, %ctaid.y;
	ld.param.u32 	%r2, [reduction_param_2];
	mov.u32 	%r3, %nctaid.x;
	mul.lo.s32 	%r4, %r3, %r1;
	cvt.u64.u32 	%rd3, %r4;
	mov.u32 	%r5, %ctaid.x;
	cvt.u64.u32 	%rd4, %r5;
	add.s64 	%rd5, %rd3, %rd4;
	mov.u32 	%r6, %ntid.x;
	cvt.u64.u32 	%rd6, %r6;
	mul.lo.s64 	%rd7, %rd5, %rd6;
	mov.u32 	%r7, %tid.x;
	cvt.u64.u32 	%rd8, %r7;
	add.s64 	%rd9, %rd7, %rd8;
	shl.b64 	%rd10, %rd9, 2;
	add.s64 	%rd11, %rd2, %rd10;
	ld.global.f32 	%f1, [%rd11];
	shr.u32 	%r8, %r2, 31;
	add.s32 	%r9, %r2, %r8;
	shr.s32 	%r10, %r9, 1;
	mul.wide.s32 	%rd12, %r10, 4;
	add.s64 	%rd13, %rd11, %rd12;
	ld.global.f32 	%f2, [%rd13];
	add.rn.f32 	%f3, %f1, %f2;
	add.s64 	%rd14, %rd1, %rd10;
	st.global.f32 	[%rd14], %f3;
	ret;
                                        // -- End function
}
