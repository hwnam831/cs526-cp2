//
// Generated by LLVM NVPTX Back-End
//

.version 5.0
.target sm_61, texmode_independent
.address_size 64

	// .globl	cal                     // -- Begin function cal
                                        // @cal
.func  (.param .b32 func_retval0) cal(
	.param .b64 cal_param_0
)
{
	.reg .f32 	%f<10>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<2>;

// %bb.0:                               // %entry
	ld.param.u64 	%rd1, [cal_param_0];
	ld.f32 	%f1, [%rd1+16];
	cvt.f64.f32 	%fd1, %f1;
	ld.f32 	%f2, [%rd1+4];
	ld.f32 	%f3, [%rd1+12];
	add.rn.f32 	%f4, %f2, %f3;
	ld.f32 	%f5, [%rd1+20];
	add.rn.f32 	%f6, %f4, %f5;
	ld.f32 	%f7, [%rd1+28];
	add.rn.f32 	%f8, %f6, %f7;
	cvt.f64.f32 	%fd2, %f8;
	fma.rn.f64 	%fd3, %fd2, 0d3FD0000000000000, %fd1;
	cvt.rn.f32.f64 	%f9, %fd3;
	st.param.f32 	[func_retval0+0], %f9;
	ret;
                                        // -- End function
}
	// .globl	demosaic                // -- Begin function demosaic
.entry demosaic(
	.param .u64 .ptr .global .align 4 demosaic_param_0,
	.param .u64 .ptr .global .align 4 demosaic_param_1,
	.param .u32 demosaic_param_2
)                                       // @demosaic
{
	.reg .f32 	%f<10>;
	.reg .b32 	%r<12>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<27>;

// %bb.0:                               // %entry
	ld.param.u64 	%rd1, [demosaic_param_0];
	ld.param.u64 	%rd2, [demosaic_param_1];
	mov.u32 	%r1, %ctaid.y;
	shl.b32 	%r2, %r1, 4;
	mov.u32 	%r3, %tid.y;
	add.s32 	%r4, %r2, %r3;
	add.s32 	%r5, %r4, 16;
	mov.u32 	%r6, %ctaid.x;
	shl.b32 	%r7, %r6, 4;
	mov.u32 	%r8, %tid.x;
	add.s32 	%r9, %r7, %r8;
	add.s32 	%r10, %r9, 16;
	cvt.u64.u32 	%rd3, %r10;
	mul.wide.u32 	%rd4, %r5, 2064;
	cvt.u64.u32 	%rd5, %r7;
	cvt.u64.u32 	%rd6, %r8;
	add.s64 	%rd7, %rd6, %rd5;
	add.s64 	%rd8, %rd7, -1;
	add.s64 	%rd9, %rd8, %rd4;
	shl.b64 	%rd10, %rd9, 2;
	add.s64 	%rd11, %rd1, %rd10;
	ld.global.f32 	%f1, [%rd11+64];
	add.s64 	%rd12, %rd4, -2064;
	add.s64 	%rd13, %rd4, %rd3;
	shl.b64 	%rd14, %rd13, 2;
	add.s64 	%rd15, %rd1, %rd14;
	ld.global.f32 	%f2, [%rd15+-8256];
	add.s64 	%rd16, %rd8, %rd12;
	shl.b64 	%rd17, %rd16, 2;
	add.s64 	%rd18, %rd1, %rd17;
	ld.global.f32 	%f3, [%rd18+64];
	add.s64 	%rd19, %rd7, %rd12;
	shl.b64 	%rd20, %rd19, 2;
	add.s64 	%rd21, %rd20, %rd1;
	ld.global.f32 	%f4, [%rd21+56];
	ld.global.f32 	%f5, [%rd11+-16448];
	cvt.f64.f32 	%fd1, %f3;
	add.rn.f32 	%f6, %f1, %f2;
	add.rn.f32 	%f7, %f6, %f4;
	add.rn.f32 	%f8, %f7, %f5;
	cvt.f64.f32 	%fd2, %f8;
	fma.rn.f64 	%fd3, %fd2, 0d3FD0000000000000, %fd1;
	cvt.rn.f32.f64 	%f9, %fd3;
	shl.b32 	%r11, %r4, 11;
	cvt.u64.u32 	%rd22, %r11;
	cvt.u64.u32 	%rd23, %r9;
	add.s64 	%rd24, %rd23, %rd22;
	shl.b64 	%rd25, %rd24, 2;
	add.s64 	%rd26, %rd2, %rd25;
	st.global.f32 	[%rd26], %f9;
	ret;
                                        // -- End function
}
